{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ce71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 28 16:42:27 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 35%   31C    P0    50W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7427b",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32d59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary dependencies\n",
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec6aabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f12d03ac138>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82b4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "LR = 3e-4\n",
    "TEMP = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea456f",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c87a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Block(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, strides):\n",
    "        super(ResNet_Block, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_chs, out_channels=out_chs,\n",
    "                      stride=strides, padding=1, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm2d(out_chs),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=out_chs, out_channels=out_chs,\n",
    "                      stride=1, padding=1, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm2d(out_chs)\n",
    "        )\n",
    "\n",
    "        if in_chs != out_chs:\n",
    "            self.id_mapping = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_chs, out_channels=out_chs,\n",
    "                          stride=strides, padding=0, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_chs))\n",
    "        else:\n",
    "            self.id_mapping = None\n",
    "        self.final_activation = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.id_mapping is not None:\n",
    "            x_ = self.id_mapping(x)\n",
    "        else:\n",
    "            x_ = x\n",
    "        return self.final_activation(x_ + out)\n",
    "\n",
    "class ResNet20Encoder(nn.Module):\n",
    "    def __init__(self, num_layers=20, num_stem_conv=16, config=(16, 32, 64)):\n",
    "        super(ResNet20Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.head_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=num_stem_conv,\n",
    "                      stride=1, padding=1, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm2d(num_stem_conv),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        num_layers_per_stage = (num_layers - 2) // 6\n",
    "        self.body_op = []\n",
    "        num_inputs = num_stem_conv\n",
    "        for i in range(len(config)):\n",
    "            for j in range(num_layers_per_stage):\n",
    "                if j == 0 and i != 0:\n",
    "                    strides = 2\n",
    "                else:\n",
    "                    strides = 1\n",
    "                self.body_op.append(ResNet_Block(num_inputs, config[i], strides))\n",
    "                num_inputs = config[i]\n",
    "        self.body_op = nn.Sequential(*self.body_op)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.final_fc = nn.Linear(config[-1], 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head_conv(x)\n",
    "        out = self.body_op(out)\n",
    "        features = self.avg_pool(out)\n",
    "        return features\n",
    "\n",
    "    \n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, num_layers=20, num_stem_conv=16, config=(16, 32, 64), projection_dim=20):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = ResNet20Encoder(num_layers=num_layers, num_stem_conv=num_stem_conv, config=config)\n",
    "        self.linear1 = nn.Linear(config[-1], config[-1], bias=False)\n",
    "        self.linear2 = nn.Linear(config[-1], projection_dim, bias=False)\n",
    "        \n",
    "    def forward(self, aug1, aug2):\n",
    "        aug1_out = self.encoder(aug1).squeeze()\n",
    "        aug1_out = self.linear1(aug1_out)\n",
    "        aug1_out = nn.ReLU()(aug1_out)\n",
    "        aug1_out = self.linear2(aug1_out)\n",
    "        \n",
    "        aug2_out = self.encoder(aug2).squeeze()\n",
    "        aug2_out = self.linear1(aug2_out)\n",
    "        aug2_out = nn.ReLU()(aug2_out)\n",
    "        aug2_out = self.linear2(aug2_out)\n",
    "        \n",
    "        return aug1_out, aug2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc54814",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7395187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRTransform:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.4, 0.4, 0.4, 0.1\n",
    "        )\n",
    "        self.simclr_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(size=(32, 32)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.simclr_transform(x), self.simclr_transform(x)\n",
    "    \n",
    "train_transform = SimCLRTransform()\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(size=(32, 32)),\n",
    "    transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e98d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be5a53",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1fa417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent(aug1_out, aug2_out, temperature=1.0):\n",
    "    batch_size = aug1_out.shape[0]\n",
    "    augs = torch.cat((aug1_out, aug2_out), dim=0)\n",
    "    sim_f = nn.CosineSimilarity(dim=2)\n",
    "#     cos_sim = sim_f(augs.unsqueeze(1), augs.unsqueeze(0))\n",
    "#     cos_sim = torch.matmul(augs, augs.T) / (torch.linalg.norm(augs, dim=1, ord=2) * torch.linalg.norm(augs, dim=1, ord=2))\n",
    "#     print(torch.linalg.norm(augs, dim=1, ord=2).shape)\n",
    "    cos_sim = torch.matmul(torch.nn.functional.normalize(augs, dim=1) , torch.nn.functional.normalize(augs, dim=1).T)\n",
    "    cos_sim /= temperature\n",
    "    \n",
    "    cos_sim_diag = torch.diag(cos_sim)\n",
    "    \n",
    "    loss = None\n",
    "    for i in range(2 * batch_size):\n",
    "        if i < batch_size:\n",
    "            positive_idx = i + batch_size\n",
    "        else:\n",
    "            positive_idx = i - batch_size\n",
    "        \n",
    "        row_loss = -torch.log(torch.exp(cos_sim[i][positive_idx]) / \n",
    "                              (torch.sum(torch.exp(cos_sim[i])) - torch.exp(cos_sim_diag[i])))\n",
    "\n",
    "        if loss == None:\n",
    "            loss = row_loss\n",
    "        else:\n",
    "            loss += row_loss\n",
    "    loss /= (2 * batch_size)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab71aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NT_Xent(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, world_size):\n",
    "        super(NT_Xent, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.world_size = world_size\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size, world_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size, world_size):\n",
    "        N = 2 * batch_size * world_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size * world_size):\n",
    "            mask[i, batch_size * world_size + i] = 0\n",
    "            mask[batch_size * world_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = 2 * self.batch_size * self.world_size\n",
    "\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        if self.world_size > 1:\n",
    "            z = torch.cat(GatherLayer.apply(z), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, self.batch_size * self.world_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size * self.world_size)\n",
    "\n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss\n",
    "    \n",
    "official_nt_xent = NT_Xent(BATCH_SIZE, TEMP, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2d77c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(projection_dim=64).cuda()\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in simclr_model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae9607",
   "metadata": {},
   "source": [
    "# loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5dcde133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbcc025b2564484b805efc91f67af1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.5249, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.4723, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.4356, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.4245, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.3197, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.4217, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.3408, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.2959, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.4305, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor(5.2785, device='cuda:0', grad_fn=<DivBackward0>) tensor(5.2785, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "simclr_model = SimCLR(projection_dim=64).cuda()\n",
    "optimizer = torch.optim.Adam(simclr_model.parameters(), lr=3e-4)\n",
    "\n",
    "best_loss = 9999999\n",
    "\n",
    "\n",
    "\n",
    "for epoch_idx in range(EPOCHS):\n",
    "    epoch_losses = 0\n",
    "    simclr_model.train()\n",
    "    \n",
    "    limiter = 10\n",
    "    for batch_idx, data in enumerate(tqdm(trainloader)):\n",
    "        image, _ = data\n",
    "        image = image\n",
    "        if batch_idx >= limiter: break\n",
    "        simclr_model.zero_grad()\n",
    "        aug1, aug2 = image\n",
    "        aug1 = aug1.cuda()\n",
    "        aug2 = aug2.cuda()\n",
    "        aug1_out, aug2_out = simclr_model(aug1, aug2)\n",
    "        print(aug1_out.shape, aug2_out.shape)\n",
    "        loss = nt_xent(aug1_out, aug2_out, temperature=TEMP)\n",
    "        official_loss = official_nt_xent(aug1_out, aug2_out)\n",
    "        print(loss, official_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses += loss\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    break\n",
    "#     epoch_losses /= len(trainloader)\n",
    "#     print(epoch_losses.item())\n",
    "    \n",
    "#     if epoch_losses < best_loss:\n",
    "#         best_loss = epoch_losses\n",
    "#         torch.save(simclr_model.state_dict(), f'simclr_model_{EPOCHS}_{BATCH_SIZE}_{TEMP}_{LR}.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797f66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
